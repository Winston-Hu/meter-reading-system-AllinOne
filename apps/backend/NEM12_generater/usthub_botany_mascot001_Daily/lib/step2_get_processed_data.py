"""
step2:
process the whole raw data generated by step1, make it be the clear data
(Currently does not include modifying data: inserting missing values, data smoothing)
1.Delete the row where meter_serial is NULL
2.Delete duplicate data for the same water meter with a time interval less than 14 minutes,
  and only keep the first one
3.Update timestamp to the nearest 15 minutes: 12:02:33 -> 12:00:00
4.Delete abnormal readings under the same water meter
    After power failure and restart, the reading is 0 or a very large number.
    How to determine the threshold requires manual adjustment.
    At present, this threshold is the most appropriate after several months.

    When data appears in the generated backwards file, it means there is a row with reading 0.
    In most cases, it is a problem with the threshold setting.
    Observe the pattern of numbers before and after 0 reading.
"""

import pandas as pd
from datetime import timedelta
import logging

input_csv = "data_merged/merged_messages.csv"
output_csv = "data_merged/processed_messages.csv"

time_interval = timedelta(minutes=15)  # Time interval used to adjust timestamps
allow_time_difference = 14  # The time interval threshold (in minutes), records shorter than this value will be deleted

logging.basicConfig(
    filename='log/daily_monitor.log',
    level=logging.INFO,  # DEBUG, INFO, WARNING, ERROR, CRITICAL
    format='%(asctime)s - %(levelname)s - %(message)s'
)


def delete_null_meter_serial(df):
    """
    Delete the row where meter_serial is NULL
    """
    df = df[df['meter_serial'].notna()]
    logging.info("Deleted rows where meter_serial is NULL")
    logging.info(f"remain {len(df)} rows")
    print("Deleted rows where meter_serial is NULL")
    print(len(df))
    return df


def delete_close_interval_rows(df):
    """
    Delete duplicate data for the same water meter with a time interval less than 14 minutes,
    and only keep the first one
    """
    logging.info("Deleting duplicate data for the same water meter with a time interval less than 14 minutes, "
                 "and only retaining the first one")
    print("Deleting duplicate data for the same water meter with a time interval less than 14 minutes, "
          "and only retaining the first one")
    df.sort_values(by=['nmi', 'timestamp'], inplace=True)
    rows_to_delete = []

    for nmi, group in df.groupby('nmi'):
        print(nmi)
        previous_row = group.iloc[0]
        for i in range(1, len(group)):
            current_row = group.iloc[i]
            current_timestamp = pd.to_datetime(current_row['timestamp'])
            previous_timestamp = pd.to_datetime(previous_row['timestamp'])
            time_difference = (current_timestamp - previous_timestamp).total_seconds() / 60

            if time_difference < allow_time_difference:
                rows_to_delete.append(current_row.name)  # 添加当前行的索引，表示要删除它
            else:
                previous_row = current_row  # 更新 previous_row 为当前行，表示这行保留下来

    df = df.drop(rows_to_delete)
    logging.info(f"Deleted duplicate rows with a time difference less than {allow_time_difference} minutes (only the first one was kept), {len(rows_to_delete)} rows deleted")
    logging.info(f"remain {len(df)} rows")
    print(f"Deleted duplicate rows with a time difference less than {allow_time_difference} minutes (only the first one was kept), {len(rows_to_delete)} rows deleted")
    print(len(df))
    return df


def update_timestamp(df):
    """
    Update timestamp to the nearest 15 minutes: 12:02:33 -> 12:00:00
    """
    logging.info("Updating timestamp to the nearest 15 minutes")
    print("Updating timestamp to the nearest 15 minutes")
    df['timestamp'] = pd.to_datetime(df['timestamp'])

    def round_to_nearest_interval(timestamp):
        rounded_minute = round(timestamp.minute / 15) * 15
        new_timestamp = timestamp.replace(minute=rounded_minute % 60, second=0, microsecond=0)
        if rounded_minute == 60:
            new_timestamp += timedelta(hours=1)
        return new_timestamp

    df['timestamp'] = df['timestamp'].apply(round_to_nearest_interval)
    logging.info("Updated all timestamps to the latest 15 minutes")
    print("Updated all timestamps to the latest 15 minutes")
    return df


def delete_invalid_readings(df):
    """
    Delete abnormal readings under the same water meter

    After power failure and restart, the reading is 0 or a very large number.
    How to determine the threshold requires manual adjustment.
    At present, this threshold is the most appropriate after several months.
    """
    low_reset_threshold = 50
    large_jump_threshold = 1000

    logging.info("Deleting abnormal readings under the same water meter")
    print("Deleting abnormal readings under the same water meter")
    rows_to_delete = set()
    df.sort_values(by=['nmi', 'timestamp'], inplace=True)
    grouped = df.groupby('nmi')
    for nmi, group in grouped:
        n = len(group)
        if n == 0:
            continue

        # === 处理“开头的 zero-run” ===
        # 若开头就是 0，则找出从开头起连续 0 的区间 [0..j]
        if n > 1 and group.iloc[0]['reading'] == 0:
            j = 0
            while j + 1 < n and group.iloc[j + 1]['reading'] == 0:
                j += 1
            # j 为开头 zero-run 的最后一个 0 的位置
            # 若 j+1 仍在组内，并且该值大于 low_reset_threshold，则认为这段 0 是异常，整段删除
            if j + 1 < n and abs(group.iloc[j + 1]['reading']) > low_reset_threshold:
                rows_to_delete.update(group.iloc[0:j + 1].index.tolist())

        # === 处理中间位置（支持“zero-run”与“极端跳点”） ===
        i = 1
        while i < n - 1:
            current_reading = group.iloc[i]['reading']
            prev_reading = group.iloc[i - 1]['reading']
            next_reading = group.iloc[i + 1]['reading']

            # 1) 连续 0（zero-run）整体判定
            if current_reading == 0:
                # 找到从 i 开始的连续 0 的结尾 j
                j = i
                while j + 1 < n and group.iloc[j + 1]['reading'] == 0:
                    j += 1

                # zero-run 区间为 [i..j]，两端邻居分别为 i-1 与 j+1
                next_val = group.iloc[j + 1]['reading'] if j + 1 < n else None
                prev_val = prev_reading  # 即 group.iloc[i-1]['reading']

                # 仅当两端邻居都存在且都“大于阈值”时，才认定为异常 0 段并整段删除
                # 这样就能保留类似 388,388,0,0,12,15（正常重置）的 0 段
                if (next_val is not None and
                        prev_val > low_reset_threshold and
                        next_val > low_reset_threshold):
                    rows_to_delete.update(group.iloc[i:j + 1].index.tolist())

                # 跳过刚处理过的整段 0
                i = j + 1
                continue

            if (abs(prev_reading - current_reading) > large_jump_threshold and
                    abs(next_reading - current_reading) > large_jump_threshold):
                rows_to_delete.add(group.iloc[i].name)
                logging.info(
                    f"There are large abnormal values, which should be caused by power failure. "
                    f"The information is {nmi} {group.iloc[i].timestamp}"
                )
                print(
                    f'There are large abnormal values, which should be caused by power failure. '
                    f'The information is {nmi} {group.iloc[i].timestamp}'
                )

            i += 1

    if rows_to_delete:
        df = df.drop(list(rows_to_delete))

    logging.info(f"Deleted rows with abnormal reading, a total of {len(rows_to_delete)} rows deleted")
    logging.info(f"remain {len(df)} rows")
    print(f"Deleted rows with abnormal reading, a total of {len(rows_to_delete)} rows deleted")
    print(len(df))
    return df


def step2_main():
    df = pd.read_csv(input_csv)

    # Delete the rows where meter_serial is NULL
    df = delete_null_meter_serial(df)

    # Delete rows with time intervals less than 14 minutes under the same nmi
    df = delete_close_interval_rows(df)

    # Update timestamp to the nearest 15 minutes
    df = update_timestamp(df)

    # Delete the rows with abnormal reading(power off and on)
    df = delete_invalid_readings(df)

    # Save the processed CSV file
    df.to_csv(output_csv, index=False)
    logging.info(f"The data is processed and saved to {output_csv}")
    print(f"The data is processed and saved to {output_csv}")


if __name__ == "__main__":
    step2_main()
